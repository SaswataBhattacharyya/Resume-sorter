{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94288da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.67.1)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\polpi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx pandas tqdm openpyxl requests numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a53e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3c1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 150.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'model': 'llama3.2:latest', 'created_at': '2024-12-23T13:59:19.9171209Z', 'message': {'role': 'assistant', 'content': 'Here is the extracted text:\\n\\nName: Arun Venu\\nAge in years: NA\\nQualification: BCA, M.Tech (Software Engineering)\\nSubject Area of Highest Qualification: Software Engineering\\nPlace of Education for Highest Qualification: BITS Pilani\\nCoding language: NA\\nSpoken language: NA\\nSkill set: Peoplesoft FSCM, PeopleTools, Oracle DB, Fluid Pages Conversion, XML/CSV conversion, EFM files Transfer, Database management\\nYears of work experience: 2 years\\nAny links given/email-ID: NA'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2662679200, 'load_duration': 27440500, 'prompt_eval_count': 940, 'prompt_eval_duration': 575000000, 'eval_count': 114, 'eval_duration': 2058000000}\n",
      "Saving results...\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ollama  # Import the Ollama package\n",
    "\n",
    "# Function to read DOCX files\n",
    "def read_docx(file_path):\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to read DOC files (if needed in the future)\n",
    "def read_doc(file_path):\n",
    "    print(\"Currently reading only DOCX files. Extend functionality if needed.\")\n",
    "    return \"\"\n",
    "\n",
    "# Function to read plain text files\n",
    "def read_txt(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to process files in a folder\n",
    "def read_files_in_folder(folder_path):\n",
    "    data = []\n",
    "    for file_name in tqdm(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith('.docx'):\n",
    "            content = read_docx(file_path)  # Use docx library for .docx files\n",
    "            data.append({\"file_name\": file_name, \"content\": content})\n",
    "        elif file_name.endswith('.txt'):\n",
    "            content = read_txt(file_path)  # Use plain text reader for .txt files\n",
    "            data.append({\"file_name\": file_name, \"content\": content})\n",
    "        elif file_name.endswith('.doc'):\n",
    "            content = read_doc(file_path)  # Placeholder for future .doc handling\n",
    "            data.append({\"file_name\": file_name, \"content\": content})\n",
    "    return data\n",
    "\n",
    "# Function to extract data using Ollama\n",
    "def extract_data_with_ollama(content, file_name):\n",
    "    try:\n",
    "        inferred_name = \" \".join(file_name.split(\".\")[0].split(\"_\")[:2]).strip()\n",
    "        prompt = (\n",
    "            f\"Extract the following information from the text in a clean, structured, and homogenous format.\\n\"\n",
    "            f\"Only extract the requested fields, and avoid adding any extra explanations or summaries.\\n\"\n",
    "            f\"Rules:\\n\"\n",
    "            f\"- Start your response with: 'Here is the extracted text:'\\n\"\n",
    "            f\"- Use 'NA' for missing information.\\n\"\n",
    "            f\"- Do not use special characters (*, -, etc.) in the response.\\n\"\n",
    "            f\"- For the Name field, prioritize extracting it from the text. If it is unclear or missing, compare it with this inferred name from the filename: {inferred_name}. The name should be only string without any special characters or numbers.\\n\"\n",
    "            f\"- Ensure all fields are included even if the value is 'NA'.\\n\"\n",
    "            f\"\\nFields to extract:\\n\"\n",
    "            f\"- Name\\n- Age in years: provide only one plausible age (positive integer) or put NA\\n\"\n",
    "            f\"- Qualification: provide only the degree like B.Tech, MCA, etc.\\n\"\n",
    "            f\"- Subject Area of Highest Qualification: like Engineering or Computer Science\\n\"\n",
    "            f\"- Place of Education for Highest Qualification\\n\"\n",
    "            f\"- Coding language\\n- Spoken language\\n- Skill set\\n\"\n",
    "            f\"- Years of work experience\\n- Any links given/email-ID.\\n\"\n",
    "            f\"\\nHere is the text: {content}\"\n",
    "        )\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.2:latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        print(\"Response:\", response)\n",
    "        \n",
    "        # Parse the response content into a dictionary\n",
    "        extracted_data = response.get(\"message\", {}).get(\"content\", \"No data extracted\")\n",
    "        # Ensure the result is returned as a dictionary\n",
    "        return {\"extracted_info\": extracted_data}\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Function to categorize file names based on keywords\n",
    "def categorize_file_name(file_name):\n",
    "    file_name_lower = file_name.lower()\n",
    "    if 'peoplesoft' in file_name_lower:\n",
    "        return 'Peoplesoft'\n",
    "    elif 'react dev' in file_name_lower:\n",
    "        return 'React Developer'\n",
    "    elif 'reactjs' in file_name_lower or 'react js' in file_name_lower:\n",
    "        return 'ReactJS Developer'\n",
    "    elif 'react' in file_name_lower:\n",
    "        return 'React'\n",
    "    else:\n",
    "        return 'Workday'\n",
    "\n",
    "# Function to save extracted data to Excel\n",
    "def save_to_excel(data, output_path):\n",
    "    df = pd.DataFrame(data)\n",
    "    # Add keyword category based on file name\n",
    "    df['Keyword_Category'] = df['file_name'].apply(categorize_file_name)\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# Main function to integrate everything\n",
    "def main(folder_path, excel_output):\n",
    "    print(\"Reading files...\")\n",
    "    files_data = read_files_in_folder(folder_path)\n",
    "\n",
    "    extracted_data = []\n",
    "    print(\"Extracting data...\")\n",
    "    for file_data in files_data:\n",
    "        extracted = extract_data_with_ollama(file_data[\"content\"], file_data[\"file_name\"])\n",
    "        extracted[\"file_name\"] = file_data[\"file_name\"]  # Add the file name to the dictionary\n",
    "        extracted_data.append(extracted)\n",
    "\n",
    "    print(\"Saving results...\")\n",
    "    save_to_excel(extracted_data, excel_output)\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = input(\"Enter the folder path containing DOCX/DOC files: \")\n",
    "    excel_output = \"extracted_dataAV.xlsx\"\n",
    "    main(folder_path, excel_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a089977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data saved to C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\formatted_excel2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_and_format_excel(input_file_path, output_file_path, column_name):\n",
    "    \"\"\"\n",
    "    Loads an Excel file, preprocesses text in the specified column to normalize formats,\n",
    "    and saves the formatted data into a new Excel file.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): Path to the input Excel file.\n",
    "        output_file_path (str): Path to save the formatted Excel file.\n",
    "        column_name (str): Name of the column to preprocess.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(input_file_path)\n",
    "\n",
    "    # Check if the specified column exists\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"The column '{column_name}' is missing in the input file.\")\n",
    "        return\n",
    "\n",
    "    def normalize_text(text):\n",
    "        \"\"\"\n",
    "        Normalizes text data to make it consistent for regex extraction.\n",
    "        Handles different delimiters, extra spaces, and line breaks.\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text  # Return as-is if empty or not a string\n",
    "        \n",
    "        # Remove extra spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text.strip())\n",
    "        \n",
    "        # Normalize delimiters (colon, dash, or inconsistent spacing)\n",
    "        text = re.sub(r\"(\\w+)\\s*[:\\-]\\s*\", r\"\\1: \", text)\n",
    "        \n",
    "        # Handle cases where data is on a new line (e.g., \"Name\\nAnil\")\n",
    "        text = re.sub(r\"(\\w+)\\n(\\w+)\", r\"\\1: \\2\", text)\n",
    "\n",
    "        text = text.replace(\":\", \"\")\n",
    "        \n",
    "        return text\n",
    "\n",
    "    # Apply normalization to the specified column\n",
    "    df[\"formatted_info\"] = df[column_name].apply(normalize_text)\n",
    "\n",
    "    # Save the updated DataFrame to a new Excel file\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "    print(f\"Formatted data saved to {output_file_path}\")\n",
    "\n",
    "# File paths\n",
    "input_file = r\"C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\extracted_data11.xlsx\"  # Input file path\n",
    "output_file = r\"C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\formatted_excel2.xlsx\"  # Output file path\n",
    "column_to_format = \"extracted_info\"   # Column to normalize\n",
    "\n",
    "# Run the preprocessing function\n",
    "preprocess_and_format_excel(input_file, output_file, column_to_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ba43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\cleaned_formatted_excel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to clean and standardize the \"formatted_info\" column\n",
    "def clean_formatted_info(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Skip if not a string\n",
    "    # Remove \"Here is the extracted text\"\n",
    "    text = text.replace(\"Here is the extracted text\", \"\").strip()\n",
    "    # Standardize specific phrases\n",
    "    text = text.replace(\"Age in years\", \"Age\")\n",
    "    text = text.replace(\"Subject Area of Highest Qualification\", \"Subject Area\")\n",
    "    text = text.replace(\"Place of Education for Highest Qualification\", \"Place of Education\")\n",
    "    text = re.sub(r\"Any links given/email ID.*\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "    return text\n",
    "\n",
    "# File paths\n",
    "input_file = r\"C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\formatted_excel2.xlsx\"\n",
    "output_file = r\"C:\\Users\\polpi\\Desktop\\data science\\project\\docker_project\\cleaned_formatted_excel.xlsx\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Apply the cleaning function to the \"formatted_info\" column\n",
    "df['formatted_info'] = df['formatted_info'].apply(clean_formatted_info)\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Processed file saved to {output_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spaCy_env)",
   "language": "python",
   "name": "spacy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
